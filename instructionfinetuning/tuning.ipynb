{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20e47d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import ssl\n",
    "import certifi\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        # Create verified SSL context\n",
    "        ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c08e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Edit the following sentence for grammar.', 'input': 'He go to the park every day.', 'output': 'He goes to the park every day.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5c7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c30d110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Provide a synonym for 'kind'.\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[99])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f089e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)    #1\n",
    "test_portion = int(len(data) * 0.1)            #2\n",
    "val_portion = len(data) - train_portion - test_portion    #3\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23347c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:         #1\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb0fc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78bfcb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)   #1\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:     #2\n",
    "        new_item = item.copy()\n",
    "        \n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        print(padded)\n",
    "        inputs = torch.tensor(padded[:-1])    #3\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)     #4\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45387f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 50256]\n",
      "[5, 6, 50256, 50256, 50256, 50256]\n",
      "[7, 8, 9, 50256, 50256, 50256]\n",
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9b7eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])     #1\n",
    "        targets = torch.tensor(padded[1:])    #2\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1506988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "\n",
    "        padded = (                               #1\n",
    "            new_item + [pad_token_id] *          #1\n",
    "            (batch_max_length - len(new_item))   #1\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])      #2\n",
    "        targets = torch.tensor(padded[1:])     #3\n",
    "\n",
    "        mask = targets == pad_token_id              #4\n",
    "        indices = torch.nonzero(mask).squeeze()     #4\n",
    "        if indices.numel() > 1:                     #4\n",
    "            targets[indices[1:]] = ignore_index     #4\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]       #5\n",
    "            targets = targets[:allowed_max_length]     #5\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "302c2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb85273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],     #1\n",
    "     [-0.5, 1.5]]      #2\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c19646b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]      #1\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60fd7659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3429999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():   #1\n",
    "#     device = torch.device(\"mps\")\"      \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "835a055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed9b09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0      #1\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0c0492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "803f232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,          #1\n",
    "    \"context_length\": 1024,       #2\n",
    "    \"drop_rate\": 0.0,             #3\n",
    "    \"qkv_bias\": True              #4\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "702865ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory (LLM-Lab) to Python path\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6688c759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from base.GPTModel import GPTModel\n",
    "from base.loadingGPTWeight import load_weights_into_gpt\n",
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "648bbe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eff2402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.generate import generate, text_to_token_ids, token_ids_to_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "023c35d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "803576bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "260e862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.evaluate import calc_loss_loader\n",
    "from base.training import train_model_simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a3c2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8258793354034424\n",
      "Validation loss: 3.761903762817383\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    ")\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72f12080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.945\n",
      "Ep 1 (Step 000015): Train loss 0.856, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.753, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.798, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.715, Val loss 0.809\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.790\n",
      "Ep 1 (Step 000050): Train loss 0.662, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.764\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.652, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.729\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.682\n",
      "Ep 1 (Step 000100): Train loss 0.502, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.555, Val loss 0.667\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.450, Val loss 0.687\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.404, Val loss 0.681\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.680\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.680\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.412, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.683\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
      "Ep 2 (Step 000170): Train loss 0.324, Val loss 0.684\n",
      "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.672\n",
      "Ep 2 (Step 000180): Train loss 0.391, Val loss 0.658\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.659\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.651\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.637\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.637\n",
      "Ep 2 (Step 000205): Train loss 0.351, Val loss 0.633\n",
      "Ep 2 (Step 000210): Train loss 0.365, Val loss 0.632\n",
      "Ep 2 (Step 000215): Train loss 0.396, Val loss 0.639\n",
      "Ep 2 (Step 000220): Train loss 0.300, Val loss 0.651\n",
      "Ep 2 (Step 000225): Train loss 0.347, Val loss 0.662\n",
      "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.657\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 117.43 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.00005, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1adbead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()                   #1\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)     #2\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5417612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b695c772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:      #1\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(               #2\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d077549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(98319) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "100%|██████████| 110/110 [07:55<00:00,  4.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e035317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"      #1\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27d6d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "379b6bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bf852cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\n",
    "        \"Ollama not running. Launch ollama before proceeding.\"\n",
    ")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d2813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
